{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAcwxYQ-W6w5"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "Standard CNNs are comprised of three types of layers: convolutional layers, pooling layers (for subsampling) and fully-connected layers.  When  these  layers  are  stacked, a CNN architecture has been formed. A simplified CNN architecture for MNIST image classification is illustrated in Figure 2.\n",
        "\n",
        "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Typical_cnn.png\"><img width=\"718\" alt=\"Typical cnn\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/512px-Typical_cnn.png\"></a>\n",
        "\n",
        "**Figure 1:** A common form of CNN architecture in which convolutional layers are stacked continuously before being passed through the pooling (subsampling) layer for subsampling, output of which are the features that will be fed to the fully connected (or dense) layers for final output. Source: Wikimedia\n",
        "\n",
        "\n",
        "It is important to note that simply understanding the overall architecture of a CNN architecture will not suffice. The creation and optimisation of these models can take quite some time, and can be quite confusing. We will now explore in detail the individual layers, detailing their hyperparameters and connectivities.\n",
        "\n",
        "## Convolutional operation\n",
        "\n",
        "### filters (i.e. kernels) and feature maps (i.e. activations)\n",
        "As we glide through the input, the scalar product is calculated for each value in that filter, or kernel (Figure 2). From this the network will learn kernels that 'fire' when they see a specific feature at a given spatial position of the input. These are commonly known as **activations**.\n",
        "\n",
        "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://d2l.ai/_images/correlation.svg\"><img width=\"500\" alt=\"Typical cnn\" src=\"https://d2l.ai/_images/correlation.svg\"></a>\n",
        "\n",
        "**Figure 2:** Illustration of a signle step in convolutional operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation:  0×0+1×1+3×2+4×3=19.\n",
        "\n",
        "Every kernel will have a corresponding activation/feature map, of which will be stacked along the depth dimension to form the full output volume from the convolutional layer.\n",
        "\n",
        "These kernels are usually small in spatial dimensionality, but spreads along the entirety of the depth of the input. When the data hits a convolutional layer, the layer convolves each filter across the spatial dimensionality of the input to produce a 2D activation map.\n",
        "\n",
        "One of the key differences compared to the MLP is that the neurons that the layers within the CNN are comprised of neurons organised into three dimensions, the spatial dimensionality of the input **(height, width, and the depth)**. The depth, or channels, is the third dimension of an activation volume, that is the number of filters/kernels/feature-maps used. Unlike standard MLPs, the neurons within any given layer will only connect to a small region (receiptive field) of the layer preceding it.\n",
        "\n",
        "### stride and padding\n",
        "We are also able to define the **stride** in which we set the depth around the spatial dimensionality of the input in order to place the receptive field. For example, if we were to set a stride as 1 then we would have a heavily overlapped receptive field producing extremely large activations. Alternatively, setting the stride to a greater number will reduce the amount of overlapping and produce an output of lower spatial dimensions.\n",
        "\n",
        "**Zero-padding** is the simple process of padding the border of the input, and is an effective method to give further control as to the dimensionality of the output volumes. It is important to understand through the use of these tehcniques, we will in turn alter the spatial dimensionality of the convolutional layers' output. We can calculate this using the following method:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVBynOv7XUId"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zppllZIYiuXP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QXfkQ6w0W6w6"
      },
      "outputs": [],
      "source": [
        "def calculate_conv_output(height, width, depth, kernel_size, zero_padding, stride):\n",
        "    # Receptive field size = kernel size.\n",
        "\n",
        "    volume_size = (height*width)*depth\n",
        "    z = (zero_padding*zero_padding)\n",
        "\n",
        "    return ((volume_size - kernel_size) + z) / stride + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VgiV_Q-W6w7"
      },
      "source": [
        "If the calculated result from this equation is not equal to a whole integer then the stride has been incorrectly set, as the neurons will be unable to fit neatly across the given input.\n",
        "\n",
        "\n",
        "See the slides for lecture10-CNNs for more information on CNN.\n",
        "Or, the standford course on CNNs https://cs231n.github.io/convolutional-networks/\n",
        "Or go through the short tutorial for the basic components in a ConvNet\n",
        "https://machinelearningmastery.com/crash-course-convolutional-neural-networks/\n",
        "\n",
        "\n",
        "## Task One: MNIST Classification\n",
        "\n",
        "Using the slides given last week, build a CNN to classify MNIST digits:\n",
        "\n",
        "Last week we reduced the data dimensionality with PCA prior to appl a feedforward neural network. This time, we'll train a network on the complete image and use a CNN, a sparsely connected network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgh5UHREfMDt"
      },
      "source": [
        "\n",
        "#### Just recall, in last practical, we learn how to build a simple fully connected neural network, aka Multilayer Perceptron (MLP) using dense layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PvyGFH_4W6w4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "from keras.backend import clear_session\n",
        "\n",
        "# Good Practice Klaxon: Free your memory from previously made models.\n",
        "clear_session()\n",
        "\n",
        "# Create a new blank model\n",
        "model = Sequential()\n",
        "# Set input of size (4,) denotes that we can accept variable amounts of data)\n",
        "model.add(Input((4,)))\n",
        "model.add(Dense(2, activation=\"relu\"))\n",
        "# And finally, add an output layer of shape 1\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Print out a summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uQFv4AOhu-v"
      },
      "source": [
        "Next, prepare the data. Notice the difference in the shape of the input data (due to the choice of different model architectures, this time a CNN in contrast to MLP used in last practical)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SLjix5EeW6w7"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# input image dimensions\n",
        "width = 28\n",
        "height = 28\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(X_dev, y_dev), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape for CNN: (nOfSamples, height, width, nOfchannels)\n",
        "X_dev = X_dev.reshape(X_dev.shape[0], height, width, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], height, width, 1)\n",
        "input_shape = (width, height, 1)\n",
        "\n",
        "\n",
        "# Make it faster.\n",
        "X_dev = X_dev.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_dev /= 255\n",
        "X_test /= 255\n",
        "print('X_dev shape:', X_dev.shape)\n",
        "print(X_dev.shape[0], 'development samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_dev = to_categorical(y_dev, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, to follow the usual procedure for ML model development we need to set aside a validation set from the original training set for model selection, i.e. to tune the hyperparametters and model architectures.\n",
        "\n",
        "Here we chose hold-out cross-validation, splitting the data using the ScikitLearn function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split).\n",
        "\n",
        "Make sure to set **the random state** for reproducibility.\n",
        "E.g.\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.33, **random_state**=42)"
      ],
      "metadata": {
        "id": "dhr92BFeSLVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the development set into training and validationn set (1/6 of total dev set)\n",
        "# Your code here:\n",
        "#\n",
        "\n"
      ],
      "metadata": {
        "id": "26NvMYG7TB2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyIf7LMuW6w8"
      },
      "source": [
        "Build your convolutional neural networks below (you can get some insiration from this [keras example](https://keras.io/examples/vision/mnist_convnet/))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CKcnyv0SW6w9"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
        "\n",
        "# Use function to define different models for reuse in experimments\n",
        "def create_cnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(28,28,1,)))\n",
        "    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25)) # Dropout 25% of the nodes of the previous layer during training\n",
        "    model.add(Flatten())     # Flatten, and add a fully connected layer\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax')) # Last layer: 10 class nodes, with dropout\n",
        "    return model\n",
        "\n",
        "model=create_cnn_model()\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egloE1oaW6w9"
      },
      "source": [
        "Note that we have about half a million parameters. With a strong optimizer like Adam, and a big dataset like MNIST, this shouldn't be a problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfsZ5rUSu_Eg"
      },
      "source": [
        "Also consider using GPU for accelerated computing if training is too slow using CPU only.\n",
        "\n",
        "In colab, you can easily add GPU to your runtime: just go to the top menu, click \"Runtime\"->\"Change runtime type\" -> \"Accelerater hardware\" is by default None, you can select \"GPU\" or \"TPU\" here.\n",
        "\n",
        "You can also upload the notebook to Kaggle and run it there with GPU accelorated training.\n",
        "\n",
        "TensorFlow and Keras will automatically execute on GPU if a GPU is available, so there’s nothing more you need to do after you’ve selected the GPU runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_FwtAQaPW6w-"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsoy3QHENhPI"
      },
      "source": [
        "**Question:**\n",
        "if GPU accelerating mode is enabled, how to change the batch size (assuming  current batch size is 32) to allow better use of the GPU?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI00mDc-N6qG"
      },
      "source": [
        "Generat learning curves by e.g.plotting the training and validation loss (or accuracy) side by side.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbfpVahSOGNb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"] # on training set\n",
        "val_loss_values = history_dict[\"val_loss\"] # on validation set\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"--\", color='green', label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"-\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYt4jUivOmcZ"
      },
      "source": [
        "**Exercise**:\n",
        "Plot the learning curve with training accuracy and validation accuracy against the epoch number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q7NF_-ZOmH4"
      },
      "outputs": [],
      "source": [
        "# Your code here:\n",
        "#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy8noYF_1Fne"
      },
      "source": [
        "## Now evaluate the trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lLzC_zHxLcL"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T-8tqYQ2KTZ"
      },
      "outputs": [],
      "source": [
        "# Classification report using scikit-learn\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred) # y_pred is an 2-d array with 10 columns\n",
        "y_predc = y_pred.argmax(axis=1) #get the class labels by choosing the class with the highest output\n",
        "y_testc = y_test.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_testc, y_predc))\n",
        "print(confusion_matrix(y_true=y_testc, y_pred=y_predc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Monitoring and visualization with TensorBoard\n",
        "To do good research or develop good models, you need rich, frequent feedback about what’s going on inside your models during your experiments. That’s the point of running experiments: to get information about how well a model performs as much information as possible.\n",
        "\n",
        "TensorBoard (www.tensorflow.org/tensorboard) is a browser-based application that you can run locally. It’s the best way to monitor everything that goes on inside your model during training. With TensorBoard, you can\n",
        "- Visually monitor metrics during training\n",
        "- Visualize your model architecture\n",
        "- Visualize histograms of activations and gradients\n",
        "- Explore embeddings in 3D\n",
        "\n",
        "The easiest way to use TensorBoard with a Keras model and the fit() method is to use the keras.callbacks.TensorBoard callback."
      ],
      "metadata": {
        "id": "_KoJADI7IK3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a log directory (whatever path and name that suits)\n",
        "!mkdir log"
      ],
      "metadata": {
        "id": "0dZmjfdMNpB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "tensorboard = keras.callbacks.TensorBoard(log_dir=\"log\")\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_data=(X_val, y_val),\n",
        "          callbacks=[tensorboard])"
      ],
      "metadata": {
        "id": "d33EjwyvIOM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model starts running, it will write logs at the target location. If you are running your Python script on a local machine, you can then launch the local TensorBoard server using the following command (note that the tensorboard executable should be already available if you have installed TensorFlow via pip; if not, you can install TensorBoard manually via pip install tensorboard):\n",
        "\n",
        "tensorboard --logdir /full_path_to_your_log_dir\n",
        "\n",
        "You can then navigate to the URL that the command returns in order to access the TensorBoard interface.\n",
        "\n",
        "If you are running your script in a Colab notebook, you can run an embedded TensorBoard instance as part of your notebook, using the following commands:"
      ],
      "metadata": {
        "id": "UaCumy5XP-IT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir log"
      ],
      "metadata": {
        "id": "ZHApBoQsQgfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YesYbBmzW6w-"
      },
      "source": [
        "**Exercise**:\n",
        "\n",
        "Try out different network architecture and hyperparameter settings, and observe the effect on performance using Tensorboard.\n",
        "\n",
        "You can also try out the classic [LeNet architecture (LeuCun et al. 1998)](https://d2l.ai/chapter_convolutional-neural-networks/lenet.html#sec-lenet), given in the [deep learning textbook d2l.ai](https://d2l.ai/index.html), see below.\n",
        " - 2 convolutional layers uses 5×5 kernel and a sigmoid activation function. The first convolutional layer has 6 output channels, while the second has 16. Each 2×2 AvgPooling operation (stride 2). The convolutional block emits an output with shape given by (batch size, number of channel, height, width).\n",
        " - 3 dense layers, with 120, 84, and 10 outputs, respectively. Because we are still performing classification, the 10-dimensional output layer corresponds to the number of possible output classes.\n",
        "\n",
        "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://d2l.ai/_images/lenet-vert.svg\"><img width=\"200\" alt=\"Typical cnn\" src=\"https://d2l.ai/_images/lenet-vert.svg\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ADgQRRjiW6w_"
      },
      "outputs": [],
      "source": [
        "# Your code\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGaWz5I2Hb7f"
      },
      "source": [
        "## Task 2 (optional): Classification using different benchmarking datasets\n",
        "\n",
        "Develop and evaluate a model with different datasets, e.g.\n",
        "- a more difficult MNIST dataset: [the Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), to load the data from keras:\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "- Cifar10 or Cifar100 dataset\n",
        "https://keras.io/api/datasets/cifar100/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5xH-eQ4H18I"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}